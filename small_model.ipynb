{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       " \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs\n",
       "with additional channel dimension) as described in the paper\n",
       "`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n",
       "\n",
       ".. math::\n",
       "\n",
       "    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
       "\n",
       "The mean and standard-deviation are calculated per-dimension over\n",
       "the mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\n",
       "of size `C` (where `C` is the input size). By default, the elements of :math:`\\gamma` are sampled\n",
       "from :math:`\\mathcal{U}(0, 1)` and the elements of :math:`\\beta` are set to 0.\n",
       "\n",
       "Also by default, during training this layer keeps running estimates of its\n",
       "computed mean and variance, which are then used for normalization during\n",
       "evaluation. The running estimates are kept with a default :attr:`momentum`\n",
       "of 0.1.\n",
       "\n",
       "If :attr:`track_running_stats` is set to ``False``, this layer then does not\n",
       "keep running estimates, and batch statistics are instead used during\n",
       "evaluation time as well.\n",
       "\n",
       ".. note::\n",
       "    This :attr:`momentum` argument is different from one used in optimizer\n",
       "    classes and the conventional notion of momentum. Mathematically, the\n",
       "    update rule for running statistics here is\n",
       "    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n",
       "    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n",
       "    new observed value.\n",
       "\n",
       "Because the Batch Normalization is done over the `C` dimension, computing statistics\n",
       "on `(N, H, W)` slices, it's common terminology to call this Spatial Batch Normalization.\n",
       "\n",
       "Args:\n",
       "    num_features: :math:`C` from an expected input of size\n",
       "        :math:`(N, C, H, W)`\n",
       "    eps: a value added to the denominator for numerical stability.\n",
       "        Default: 1e-5\n",
       "    momentum: the value used for the running_mean and running_var\n",
       "        computation. Can be set to ``None`` for cumulative moving average\n",
       "        (i.e. simple average). Default: 0.1\n",
       "    affine: a boolean value that when set to ``True``, this module has\n",
       "        learnable affine parameters. Default: ``True``\n",
       "    track_running_stats: a boolean value that when set to ``True``, this\n",
       "        module tracks the running mean and variance, and when set to ``False``,\n",
       "        this module does not track such statistics and always uses batch\n",
       "        statistics in both training and eval modes. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C, H, W)`\n",
       "    - Output: :math:`(N, C, H, W)` (same shape as input)\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # With Learnable Parameters\n",
       "    >>> m = nn.BatchNorm2d(100)\n",
       "    >>> # Without Learnable Parameters\n",
       "    >>> m = nn.BatchNorm2d(100, affine=False)\n",
       "    >>> input = torch.randn(20, 100, 35, 45)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`:\n",
       "    https://arxiv.org/abs/1502.03167\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     BatchNorm2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallNet(\n",
      "  (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (batch): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class smallNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(smallNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv = nn.Conv2d(3, 64, 3)\n",
    "        # batch         \n",
    "        self.batch = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        # relu\n",
    "        self.relu = nn.ReLU()\n",
    "        # max pooling        \n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "#         # full connected         \n",
    "#         self.fc = nn.Linear(14400, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.conv(x)\n",
    "        print(x.size())\n",
    "        x = self.batch(x)\n",
    "        print(x.size())\n",
    "        x = self.relu(x)\n",
    "        print(x.size())\n",
    "        x = self.maxpool(x)\n",
    "        print(x.size())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        print(x.size())\n",
    "        return nn.Linear(x.size()[1], 1)(x)\n",
    "#         # Max pooling over a (2, 2) window\n",
    "#         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "#         # If the size is a square you can only specify a single number\n",
    "#         x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "#         x = x.view(-1, self.num_flat_features(x))\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = smallNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "for param in params:\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 32, 32])\n",
      "torch.Size([3, 64, 30, 30])\n",
      "torch.Size([3, 64, 30, 30])\n",
      "torch.Size([3, 64, 30, 30])\n",
      "torch.Size([3, 64, 15, 15])\n",
      "torch.Size([3, 14400])\n",
      "tensor([[0.0154],\n",
      "        [0.0214],\n",
      "        [0.2525]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 3, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "During training, randomly zeroes some of the elements of the input\n",
       "tensor with probability :attr:`p` using samples from a Bernoulli\n",
       "distribution. Each channel will be zeroed out independently on every forward\n",
       "call.\n",
       "\n",
       "This has proven to be an effective technique for regularization and\n",
       "preventing the co-adaptation of neurons as described in the paper\n",
       "`Improving neural networks by preventing co-adaptation of feature\n",
       "detectors`_ .\n",
       "\n",
       "Furthermore, the outputs are scaled by a factor of :math:`\\frac{1}{1-p}` during\n",
       "training. This means that during evaluation the module simply computes an\n",
       "identity function.\n",
       "\n",
       "Args:\n",
       "    p: probability of an element to be zeroed. Default: 0.5\n",
       "    inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(*)`. Input can be of any shape\n",
       "    - Output: :math:`(*)`. Output is of the same shape as input\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Dropout(p=0.2)\n",
       "    >>> input = torch.randn(20, 16)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _Improving neural networks by preventing co-adaptation of feature\n",
       "    detectors: https://arxiv.org/abs/1207.0580\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/torch/nn/modules/dropout.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-18 10:13:31.992813\n",
      "2020-02-18 10:13:31.992813+00:00\n",
      "2020-02-18 18:13:31.992813+08:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timezone,timedelta\n",
    "dt = datetime.utcnow()\n",
    "print(dt)\n",
    "dt = dt.replace(tzinfo=timezone.utc)\n",
    "print(dt)\n",
    "tzutc_8 = timezone(timedelta(hours=8))\n",
    "local_dt = dt.astimezone(tzutc_8)\n",
    "print(local_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(local_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-18 18:13:31.992813+08:00\n"
     ]
    }
   ],
   "source": [
    "print(str(local_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoints/checkpoints_pure/checkpoint-2020-02-20 13:38:29.968086+08:00/312.pth.tar', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
